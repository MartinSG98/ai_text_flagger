# AI Text Flagger

ðŸ”— **Frontend repo:** [ai_text_flagger_ui](https://github.com/MartinSG98/ai_text_flagger_ui)

An application that detects AI-generated text using a fine-tuned BERT model. It can identify whether text was written by a human or generated by various AI models (GPT-4, Claude, Gemini, etc.) and suggests which model likely wrote it.

Built with BERT (NLP), FastAPI (backend), and React + TypeScript (frontend).

## Features

- Detects AI-generated vs human-written text
- Identifies which AI model likely generated the text (GPT-4, Claude, Gemini, etc.)
- Accepts text input via paste or file upload (.txt, .docx, .pdf) - changes might be made in the future
- Returns confidence scores for predictions

## Training Data

**Human-written text (~160k samples):**

| Source                                                                                   | Description                                 | Samples |
| ---------------------------------------------------------------------------------------- | ------------------------------------------- | ------- |
| [Human Written Text](https://www.kaggle.com/datasets/youssefelebiary/human-written-text) | CNN/DailyMail, Wikipedia, Project Gutenberg | ~60k    |
| [Pushshift Reddit](https://huggingface.co/datasets/fddemarco/pushshift-reddit)           | Casual posts and discussions                | 100k    |

**AI-generated text (~241k samples):**

| Source                                                                                   | Description                                               | Samples |
| ---------------------------------------------------------------------------------------- | --------------------------------------------------------- | ------- |
| Custom prompts                                                                           | Direct outputs from GPT-4, Claude, Gemini, LLaMA, Mistral | ~1k     |
| [AI Text Detection Pile](https://huggingface.co/datasets/artem9k/ai-text-detection-pile) | GPT2, GPT3, ChatGPT, GPTJ outputs                         | 240k    |

AI samples are distributed across 12 model labels: GPT-4, GPT-4o, GPT-3.5-turbo, GPT 5-instant, GPT 5-thinking, GPT 5.1, Gemini 3 Pro, Claude Haiku 4.5, Claude Sonnet 4.5, Claude Opus 4.5, LLaMA, and Mistral.

**Note:** The AI Text Detection Pile contains generic AI-generated text without specific model labels. Samples were distributed evenly across model folders for training purposes.

**Total dataset: ~400k samples**

## Tech Stack

**Model**

- BERT Large (fine-tuned for text classification)
- Hugging Face Transformers
- PyTorch

**Backend**

- FastAPI
- Python 3.11

**Frontend**

- React
- TypeScript
- TailwindCSS
- Mantine UI

## Setup

### Backend

Prerequisites:

- Python 3.11+
- NVIDIA GPU (for training)

1. Create virtual environment

```bash
python -m venv venv
.\venv\Scripts\Activate  # Windows
source venv/bin/activate  # Linux/Mac
```

2. Install dependencies - you can also use UV to install everything at once and faster

```bash
pip install -r requirements.txt
```

3. Train the model

```bash
python src/model.py
```

4. Run the API

```bash
uvicorn src.api:app --reload
```

### Frontend

Prerequisites: Node.js 18+

See [ai_text_flagger_ui](https://github.com/MartinSG98/ai_text_flagger_ui) for frontend setup.

## API Endpoints

### Health Check

`GET /health`

Returns `{"status": "ok"}`

### Predict from Text

`POST /predict`

Request:

```json
{ "text": "Your text to analyze..." }
```

Response:

```json
{ "prediction": "Human", "confidence": 0.94, "ai_probability": 0.06 }
```

### Predict from File

`POST /predict/file`

Accepts: `.txt`, `.docx`, `.pdf`

Response:

```json
{ "prediction": "GPT-4", "confidence": 0.87, "ai_probability": 0.92 }
```

## Project Structure

```
ai_text_flagger/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py    # Load and unify datasets
â”‚   â”œâ”€â”€ preprocess.py     # Clean text and split data
â”‚   â”œâ”€â”€ model.py          # BERT training and prediction
â”‚   â””â”€â”€ api.py            # FastAPI endpoints
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ dataset.json      # Unified dataset
â”‚   â”œâ”€â”€ train.json        # Training split
â”‚   â”œâ”€â”€ val.json          # Validation split
â”‚   â”œâ”€â”€ test.json         # Test split
â”‚   â””â”€â”€ model/            # Trained model files
â”œâ”€â”€ Datasets/             # Raw data (not in repo)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Hardware Notes

Developed and trained on:

- CPU: AMD Ryzen 9 9900X
- GPU: NVIDIA RTX 5090 (32GB VRAM)

**RTX 50-series users:** The 5090 requires PyTorch nightly build (stable doesn't support sm_120 yet):

```bash
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu128
```

**Inference:** The trained model can run on any CUDA-compatible GPU or CPU (slower).
