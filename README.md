# AI Text Flagger

ðŸ”— **Frontend repo:** [ai_text_flagger_ui](https://github.com/MartinSG98/ai_text_flagger_ui)

An application that detects AI-generated text using a fine-tuned BERT model. It identifies whether text was written by a human or generated by AI.

Built with BERT (NLP), FastAPI (backend), and React + TypeScript (frontend).

## Features

- Binary classification: Human vs AI-generated text
- Accepts text input via paste or file upload (.txt, .docx, .pdf) - changes might be made in the future
- Returns confidence scores and AI probability
- API key authentication for protected endpoints

## Training Data

**Human-written text (~160k samples):**

| Source                                                                                   | Description                                 | Samples |
| ---------------------------------------------------------------------------------------- | ------------------------------------------- | ------- |
| [Human Written Text](https://www.kaggle.com/datasets/youssefelebiary/human-written-text) | CNN/DailyMail, Wikipedia, Project Gutenberg | ~60k    |
| [Pushshift Reddit](https://huggingface.co/datasets/fddemarco/pushshift-reddit)           | Casual posts and discussions                | 100k    |

**AI-generated text (~241k samples):**

| Source                                                                                   | Description                                               | Samples |
| ---------------------------------------------------------------------------------------- | --------------------------------------------------------- | ------- |
| Custom prompts                                                                           | Direct outputs from GPT-4, Claude, Gemini, LLaMA, Mistral | ~1k     |
| [AI Text Detection Pile](https://huggingface.co/datasets/artem9k/ai-text-detection-pile) | GPT2, GPT3, ChatGPT, GPTJ outputs                         | 240k    |

**Note:** All AI samples are labeled as "AI" for binary classification. The model distinguishes between human and AI-generated text, not between specific AI models.

**Total dataset: ~400k samples**

Tokenization time: ~90 mins
Training time: ~18 hours

## Tech Stack

**Model**

- BERT Large Cased (fine-tuned for binary classification)
- Hugging Face Transformers
- PyTorch

**Backend**

- FastAPI
- Python 3.11

**Frontend**

- React
- TypeScript
- TailwindCSS
- Mantine UI

## Setup

### Backend

Prerequisites:

- Python 3.11+
- NVIDIA GPU (for training)

1. Create virtual environment

```bash
python -m venv venv
.\venv\Scripts\Activate  # Windows
source venv/bin/activate  # Linux/Mac
```

2. Install dependencies - you can also use UV to install everything at once and faster

```bash
pip install -r requirements.txt
```

3. Configure environment variables

```bash
# Create .env file in project root
cp .env.example .env

# Edit .env and set your API key
API_KEY=your-secret-key-here
```

Generate a secure key with Python:

```python
import secrets
print(secrets.token_urlsafe(32))
```

4. Train the model

```bash
# Step 1: Load and unify all datasets into output/dataset.json
python src/data_loader.py

# Step 2: Clean text, convert to binary labels (Human/AI), split into train/val/test
python src/preprocess.py

# Step 3: Train the BERT model (~20 hours on RTX 5090)
python src/model.py
```

5. Run the API

```bash
uvicorn src.api:app --reload
```

### Frontend

Prerequisites: Node.js 18+

See [ai_text_flagger_ui](https://github.com/MartinSG98/ai_text_flagger_ui) for frontend setup.

## API Endpoints

All `/predict` endpoints require the `x-api-key` header.

### Health Check

`GET /health`

Returns `{"status": "ok"}`

No authentication required.

### Predict from Text

`POST /predict`

Headers:

```
x-api-key: your-api-key
Content-Type: application/json
```

Request:

```json
{ "text": "Your text to analyze..." }
```

Response:

```json
{ "prediction": "Human", "confidence": 0.94, "ai_probability": 0.06 }
```

### Predict from File

`POST /predict/file`

Headers:

```
x-api-key: your-api-key
```

Accepts: `.txt`, `.docx`, `.pdf`

Response:

```json
{ "prediction": "AI", "confidence": 0.87, "ai_probability": 0.87 }
```

## Project Structure

```
ai_text_flagger/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py    # Load and unify datasets
â”‚   â”œâ”€â”€ preprocess.py     # Clean text, convert to binary labels, split data
â”‚   â”œâ”€â”€ model.py          # BERT training and prediction
â”‚   â””â”€â”€ api.py            # FastAPI endpoints with auth
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ dataset.json      # Unified dataset
â”‚   â”œâ”€â”€ train.json        # Training split
â”‚   â”œâ”€â”€ val.json          # Validation split
â”‚   â”œâ”€â”€ test.json         # Test split
â”‚   â””â”€â”€ model/            # Trained model files
â”œâ”€â”€ Datasets/             # Raw data (not in repo)
â”œâ”€â”€ .env                  # API key (not in repo)
â”œâ”€â”€ .env.example          # Example env file
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Hardware Notes

Developed and trained on:

- CPU: AMD Ryzen 9 9900X
- GPU: ZOTAC GAMING GeForce RTX 5090 SOLID
- G.SKILL Ripjaws M5 Neo RGB 48GB (2x24GB) 6000MT/s DDR5 CL 30

**RTX 50-series users:** As of today 05/12/2025 The 5090 requires PyTorch nightly build (stable doesn't support sm_120 yet):

```bash
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu128
```

**Inference:** The trained model can run on any CUDA-compatible GPU or CPU (slower).
